{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üö¶ Reshaping Traffic: Spatio-Temporal Traffic Forecasting & Control\n",
        "\n",
        "**Complete Project Consolidation**\n",
        "\n",
        "This notebook contains the entire traffic forecasting and routing system:\n",
        "- **Model Architecture**: Graph Attention Networks + Mamba (SSM) for spatio-temporal forecasting\n",
        "- **Training Pipeline**: Complete training loop with early stopping, checkpoints, and logging\n",
        "- **Evaluation**: Model evaluation with uncertainty quantification\n",
        "- **Traffic Routing**: Closed-loop traffic control system (Model-2)\n",
        "- **Simulation**: Traffic flow simulator for closed-loop evaluation\n",
        "\n",
        "---\n",
        "\n",
        "## Project Structure\n",
        "\n",
        "1. **Imports & Dependencies**\n",
        "2. **Utility Functions** (metrics, seed, early stopping, checkpoint, logger, uncertainty)\n",
        "3. **Model Components** (GAT, Mamba, ST-Mamba blocks, multi-scale temporal, dynamic graph, uncertainty head)\n",
        "4. **Main Model** (NewtonGraphMamba)\n",
        "5. **Dataset** (TrafficDataset)\n",
        "6. **Training Pipeline**\n",
        "7. **Evaluation Pipeline**\n",
        "8. **Traffic Routing Controller** (Model-2)\n",
        "9. **Traffic Simulator**\n",
        "10. **Example Usage & Demo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import logging\n",
        "import csv\n",
        "import os\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# NetworkX for routing\n",
        "try:\n",
        "    import networkx as nx\n",
        "except ImportError:\n",
        "    print(\"Warning: networkx not installed. Traffic routing features will be limited.\")\n",
        "    nx = None\n",
        "\n",
        "# Mamba SSM with fallback\n",
        "try:\n",
        "    from mamba_ssm import Mamba\n",
        "    MAMBA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Warning: mamba_ssm not found. Using CPU placeholder.\")\n",
        "    MAMBA_AVAILABLE = False\n",
        "    \n",
        "    class Mamba(nn.Module):\n",
        "        def __init__(self, d_model, d_state=16, d_conv=4, expand=2):\n",
        "            super().__init__()\n",
        "            self.in_proj = nn.Linear(d_model, d_model * 2)\n",
        "            self.out_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.out_proj(F.silu(self.in_proj(x))[:, :, :x.shape[-1]])\n",
        "\n",
        "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
        "print(f\"‚úÖ Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
        "print(f\"‚úÖ Mamba SSM: {'Available' if MAMBA_AVAILABLE else 'Using fallback'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Metrics\n",
        "# =======================\n",
        "def masked_mae(pred, true, eps=1e-5):\n",
        "    \"\"\"Masked Mean Absolute Error\"\"\"\n",
        "    mask = (true != 0).float()\n",
        "    loss = torch.abs(pred - true)\n",
        "    return (loss * mask).sum() / (mask.sum() + eps)\n",
        "\n",
        "def masked_rmse(pred, true, eps=1e-5):\n",
        "    \"\"\"Masked Root Mean Squared Error\"\"\"\n",
        "    mask = (true != 0).float()\n",
        "    loss = (pred - true) ** 2\n",
        "    return torch.sqrt((loss * mask).sum() / (mask.sum() + eps))\n",
        "\n",
        "def masked_mape(pred, true, eps=1e-5):\n",
        "    \"\"\"Masked Mean Absolute Percentage Error\"\"\"\n",
        "    mask = (true != 0).float()\n",
        "    loss = torch.abs((pred - true) / (true + eps))\n",
        "    return (loss * mask).sum() / (mask.sum() + eps)\n",
        "\n",
        "# =======================\n",
        "# Seed for Reproducibility\n",
        "# =======================\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# =======================\n",
        "# Early Stopping\n",
        "# =======================\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10):\n",
        "        self.patience = patience\n",
        "        self.best = float(\"inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def load(self, best, counter):\n",
        "        self.best = best\n",
        "        self.counter = counter\n",
        "\n",
        "    def step(self, loss):\n",
        "        if loss < self.best:\n",
        "            self.best = loss\n",
        "            self.counter = 0\n",
        "            return False\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            return self.counter >= self.patience\n",
        "\n",
        "# =======================\n",
        "# Checkpoint Management\n",
        "# =======================\n",
        "def save_checkpoint(state, path=\"checkpoint.pt\"):\n",
        "    torch.save(state, path)\n",
        "\n",
        "def load_checkpoint(model, optimizer, scheduler, path=\"checkpoint.pt\"):\n",
        "    if not os.path.exists(path):\n",
        "        return 0, float(\"inf\"), 0\n",
        "    ckpt = torch.load(path, map_location=\"cpu\")\n",
        "    model.load_state_dict(ckpt[\"model\"])\n",
        "    optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "    scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
        "    return ckpt[\"epoch\"], ckpt[\"best_val\"], ckpt[\"early_stop_counter\"]\n",
        "\n",
        "# =======================\n",
        "# CSV Logger\n",
        "# =======================\n",
        "class CSVLogger:\n",
        "    def __init__(self, path=\"training_metrics.csv\"):\n",
        "        self.path = Path(path)\n",
        "        if not self.path.exists():\n",
        "            with open(self.path, \"w\", newline=\"\") as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([\"epoch\", \"train_loss\", \"val_mae\"])\n",
        "\n",
        "    def log(self, epoch, train_loss, val_mae):\n",
        "        with open(self.path, \"a\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([epoch, train_loss, val_mae])\n",
        "\n",
        "# =======================\n",
        "# Uncertainty Quantification (implementing mc dropout)\n",
        "# =======================\n",
        "@torch.no_grad()\n",
        "def mc_dropout_predict(model, X, adj, runs=20):\n",
        "    \"\"\"Monte-Carlo Dropout Inference for uncertainty estimation\"\"\"\n",
        "    model.train()  # IMPORTANT: enable dropout\n",
        "    preds = []\n",
        "    for _ in range(runs):\n",
        "        preds.append(model(X, adj))\n",
        "    preds = torch.stack(preds, dim=0)\n",
        "    mean = preds.mean(dim=0)\n",
        "    std = preds.std(dim=0)\n",
        "    model.eval()\n",
        "    return mean, std\n",
        "\n",
        "print(\"‚úÖ Utility functions loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================\n",
        "# GAT Layer (Graph Attention Network)\n",
        "# =======================\n",
        "class GATLayer(nn.Module):\n",
        "    \"\"\"Multi-head Graph Attention Network layer for spatial modeling\"\"\"\n",
        "    def __init__(self, in_features, out_features, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert out_features % num_heads == 0\n",
        "        \n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = out_features // num_heads\n",
        "        \n",
        "        self.Wq = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.Wk = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.Wv = nn.Linear(in_features, out_features, bias=False)\n",
        "        \n",
        "        self.out_proj = nn.Linear(out_features, out_features)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, h, adj):\n",
        "        B, N, _ = h.shape\n",
        "        \n",
        "        # Multi-head attention\n",
        "        q = self.Wq(h).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        k = self.Wk(h).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        v = self.Wv(h).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        \n",
        "        # Attention scores\n",
        "        scores = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(self.head_dim)\n",
        "        \n",
        "        # Mask disconnected nodes\n",
        "        mask = (adj == 0).view(1, 1, N, N)\n",
        "        scores = scores.masked_fill(mask, -1e9)\n",
        "        \n",
        "        attn = self.dropout(F.softmax(scores, dim=-1))\n",
        "        out = torch.matmul(attn, v)\n",
        "        \n",
        "        out = out.transpose(1, 2).reshape(B, N, -1)\n",
        "        return h + self.out_proj(out)  # Residual connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Multi-Scale Temporal Encoder\n",
        "# =======================\n",
        "class TemporalBlock(nn.Module):\n",
        "    \"\"\"Temporal modeling block using Mamba\"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.mamba = Mamba(d_model=dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x: [B, T, N, F]\n",
        "        B, T, N, F = x.shape\n",
        "        x = x.view(B * N, T, F)\n",
        "        out = self.mamba(x)\n",
        "        return out[:, -1].view(B, N, F)  # Take last timestep\n",
        "\n",
        "class MultiScaleTemporal(nn.Module):\n",
        "    \"\"\"Multi-scale temporal encoder with attention fusion\"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.short = TemporalBlock(dim)  # 5‚Äì15 min\n",
        "        self.mid = TemporalBlock(dim)    # 30‚Äì60 min\n",
        "        self.long = TemporalBlock(dim)   # 1‚Äì2 hour\n",
        "        self.attn = nn.Linear(dim, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x: [B, T>=48, N, F]\n",
        "        short = x[:, -12:]      # Last 12 timesteps\n",
        "        mid = x[:, -24::2]      # Last 24 timesteps, every 2nd\n",
        "        long = x[:, -48::4]     # Last 48 timesteps, every 4th\n",
        "        \n",
        "        f_s = self.short(short)\n",
        "        f_m = self.mid(mid)\n",
        "        f_l = self.long(long)\n",
        "        \n",
        "        # Attention-weighted fusion\n",
        "        scores = torch.stack([\n",
        "            self.attn(f_s),\n",
        "            self.attn(f_m),\n",
        "            self.attn(f_l)\n",
        "        ], dim=0)\n",
        "        \n",
        "        weights = torch.softmax(scores, dim=0)\n",
        "        return weights[0] * f_s + weights[1] * f_m + weights[2] * f_l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Dynamic Graph Learner\n",
        "# =======================\n",
        "class DynamicGraphLearner(nn.Module):\n",
        "    \"\"\"Learns dynamic graph structure adapting to traffic conditions\"\"\"\n",
        "    def __init__(self, num_nodes, dim):\n",
        "        super().__init__()\n",
        "        self.node_emb = nn.Parameter(torch.randn(num_nodes, dim))\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "    \n",
        "    def forward(self, h, A_static):\n",
        "        \"\"\"\n",
        "        h: [B, N, F] - node features\n",
        "        A_static: [N, N] - static adjacency matrix\n",
        "        \"\"\"\n",
        "        q = self.proj(h)  # Query from current state\n",
        "        k = self.node_emb.unsqueeze(0)  # Key from learned embeddings\n",
        "        \n",
        "        # Compute dynamic adjacency\n",
        "        A_dyn = torch.softmax(\n",
        "            torch.matmul(q, k.transpose(-1, -2)), dim=-1\n",
        "        )\n",
        "        \n",
        "        # Combine static and dynamic (weighted fusion)\n",
        "        return 0.7 * A_static + 0.3 * A_dyn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Uncertainty Head (Probabilistic Output)\n",
        "# =======================\n",
        "class ProbabilisticHead(nn.Module):\n",
        "    \"\"\"Probabilistic prediction head with dropout for uncertainty\"\"\"\n",
        "    def __init__(self, dim, horizon=12):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(dim, horizon)  # Output H predictions per node\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x: [B, N, F] -> [B, N, H]\n",
        "        return self.fc(self.dropout(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================\n",
        "# ST-Mamba Block (Spatio-Temporal)\n",
        "# =======================\n",
        "class STMambaBlock(nn.Module):\n",
        "    \"\"\"Spatio-temporal block combining GAT and Mamba\"\"\"\n",
        "    def __init__(self, d_model, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.gat = GATLayer(d_model, d_model, num_heads, dropout)\n",
        "        self.norm_s = nn.LayerNorm(d_model)\n",
        "        \n",
        "        self.mamba = Mamba(d_model)\n",
        "        self.norm_t = nn.LayerNorm(d_model)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, x, adj):\n",
        "        \"\"\"\n",
        "        x: [B, T, N, F]\n",
        "        adj: [N, N]\n",
        "        \"\"\"\n",
        "        B, T, N, F = x.shape\n",
        "        \n",
        "        # Spatial modeling (across nodes)\n",
        "        x_s = x.view(B * T, N, F)\n",
        "        x_s = self.norm_s(x_s + self.dropout(self.gat(x_s, adj)))\n",
        "        x = x_s.view(B, T, N, F)\n",
        "        \n",
        "        # Temporal modeling (across time)\n",
        "        x_t = x.permute(0, 2, 1, 3).reshape(B * N, T, F)\n",
        "        x_t = self.norm_t(x_t + self.dropout(self.mamba(x_t)))\n",
        "        x = x_t.view(B, N, T, F).permute(0, 2, 1, 3)\n",
        "        \n",
        "        return x\n",
        "\n",
        "print(\"‚úÖ Model components loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Main Model: NewtonGraphMamba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NewtonGraphMamba(nn.Module):\n",
        "    \"\"\"\n",
        "    Complete spatio-temporal traffic forecasting model\n",
        "    \n",
        "    Architecture:\n",
        "    - Input projection\n",
        "    - Multi-scale temporal encoder\n",
        "    - Dynamic graph learner\n",
        "    - ST-Mamba blocks (spatial + temporal)\n",
        "    - Probabilistic prediction head\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features=5,\n",
        "        d_model=64,\n",
        "        num_nodes=100,\n",
        "        num_layers=4,\n",
        "        num_heads=4,\n",
        "        prediction_horizon=12\n",
        "    ):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.num_nodes = num_nodes\n",
        "        self.horizon = prediction_horizon\n",
        "        \n",
        "        # Input projection\n",
        "        self.input_proj = nn.Linear(in_features, d_model)\n",
        "        \n",
        "        # Multi-scale temporal encoder\n",
        "        self.multi_scale_temporal = MultiScaleTemporal(d_model)\n",
        "        \n",
        "        # Dynamic graph learner\n",
        "        self.graph_learner = DynamicGraphLearner(num_nodes, d_model)\n",
        "        \n",
        "        # ST-Mamba blocks\n",
        "        self.layers = nn.ModuleList([\n",
        "            STMambaBlock(d_model, num_heads)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        \n",
        "        # Probabilistic prediction head\n",
        "        self.head = ProbabilisticHead(d_model, prediction_horizon)\n",
        "    \n",
        "    def forward(self, x, adj_static):\n",
        "        \"\"\"\n",
        "        x: [B, T>=48, N, F] - input traffic data\n",
        "        adj_static: [N, N] - static adjacency matrix\n",
        "        Returns: [B, N, H] - traffic predictions for H time steps\n",
        "        \"\"\"\n",
        "        # Input projection\n",
        "        x = self.input_proj(x)\n",
        "        \n",
        "        # Multi-scale temporal fusion\n",
        "        h = self.multi_scale_temporal(x)  # [B, N, F]\n",
        "        \n",
        "        # Dynamic graph learning\n",
        "        adj = self.graph_learner(h, adj_static)\n",
        "        \n",
        "        # Expand temporal dimension for ST blocks\n",
        "        h = h.unsqueeze(1).repeat(1, self.horizon, 1, 1)\n",
        "        \n",
        "        # ST-Mamba blocks\n",
        "        for layer in self.layers:\n",
        "            h = layer(h, adj)\n",
        "        \n",
        "        # Prediction head - take last timestep and predict all H horizons\n",
        "        # h[:, -1] is [B, N, F], head outputs [B, N, H]\n",
        "        out = self.head(h[:, -1])  # [B, N, H]\n",
        "        \n",
        "        return out  # [B, N, H]\n",
        "\n",
        "print(\"‚úÖ Main model loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Dataset: TrafficDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrafficDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Traffic dataset with sliding window approach\n",
        "    \n",
        "    Args:\n",
        "        data: np.ndarray [T, N, F] - time series data\n",
        "        history_len: history window size (default: 12)\n",
        "        horizon: prediction horizon (default: 12)\n",
        "        mean: normalization mean (optional)\n",
        "        std: normalization std (optional)\n",
        "    \"\"\"\n",
        "    def __init__(self, data, history_len=12, horizon=12, mean=None, std=None):\n",
        "        self.history_len = history_len\n",
        "        self.horizon = horizon\n",
        "        \n",
        "        # Compute normalization statistics\n",
        "        if mean is None:\n",
        "            self.mean = data.mean()\n",
        "            self.std = data.std() + 1e-6\n",
        "        else:\n",
        "            self.mean = mean\n",
        "            self.std = std\n",
        "        \n",
        "        # Normalize data\n",
        "        self.data = (data - self.mean) / self.std\n",
        "        \n",
        "        # Create sliding windows\n",
        "        self.X, self.Y = self._create_windows()\n",
        "    \n",
        "    def _create_windows(self):\n",
        "        \"\"\"Create input-output pairs using sliding window\"\"\"\n",
        "        X, Y = [], []\n",
        "        T = self.data.shape[0]\n",
        "        \n",
        "        for t in range(T - self.history_len - self.horizon):\n",
        "            X.append(self.data[t:t+self.history_len])\n",
        "            Y.append(self.data[t+self.history_len:t+self.history_len+self.horizon, :, 0])\n",
        "            # Target = first feature (traffic speed)\n",
        "        \n",
        "        return torch.tensor(X, dtype=torch.float32), torch.tensor(Y, dtype=torch.float32)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "print(\"‚úÖ Dataset class loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def auto_accumulation(device_mem_gb):\n",
        "    \"\"\"Auto-configure batch size and gradient accumulation based on GPU memory\"\"\"\n",
        "    if device_mem_gb <= 4:\n",
        "        return 4, 8  # effective batch = 32\n",
        "    elif device_mem_gb <= 6:\n",
        "        return 8, 4\n",
        "    else:\n",
        "        return 8, 8\n",
        "\n",
        "def train_model(\n",
        "    data_path=\"data/metr_la/metr_la.npz\",\n",
        "    adj_path=\"data/metr_la/adj.npy\",\n",
        "    max_epochs=500,\n",
        "    device_mem_gb=4,\n",
        "    seed=42\n",
        "):\n",
        "    \"\"\"Complete training pipeline\"\"\"\n",
        "    \n",
        "    # Setup\n",
        "    set_seed(seed)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # Logging\n",
        "    logging.basicConfig(\n",
        "        filename=\"training.log\",\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s | %(message)s\"\n",
        "    )\n",
        "    logger = CSVLogger()\n",
        "    \n",
        "    # Load data\n",
        "    data = np.load(data_path)[\"data\"]\n",
        "    adj = torch.tensor(np.load(adj_path)).float().to(device)\n",
        "    \n",
        "    # Train/val split (70/10)\n",
        "    T = len(data)\n",
        "    train_data = data[:int(0.7 * T)]\n",
        "    val_data = data[int(0.7 * T):int(0.8 * T)]\n",
        "    \n",
        "    # Create datasets\n",
        "    train_ds = TrafficDataset(train_data)\n",
        "    val_ds = TrafficDataset(val_data, mean=train_ds.mean, std=train_ds.std)\n",
        "    \n",
        "    # Data loaders\n",
        "    batch_size, grad_accum_steps = auto_accumulation(device_mem_gb)\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, pin_memory=True)\n",
        "    \n",
        "    # Model\n",
        "    model = NewtonGraphMamba(\n",
        "        in_features=data.shape[-1],\n",
        "        num_nodes=data.shape[1]\n",
        "    ).to(device)\n",
        "    \n",
        "    # Optimizer & scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, patience=5)\n",
        "    scaler = GradScaler(enabled=torch.cuda.is_available())\n",
        "    \n",
        "    # Early stopping & checkpoint\n",
        "    early_stop = EarlyStopping(patience=10)\n",
        "    start_epoch, best_val, counter = load_checkpoint(model, optimizer, scheduler)\n",
        "    early_stop.load(best_val, counter)\n",
        "    \n",
        "    print(f\"‚ñ∂ Resuming from epoch {start_epoch}\")\n",
        "    print(f\"‚ñ∂ Batch size: {batch_size}, Gradient accumulation: {grad_accum_steps}\")\n",
        "    \n",
        "    # Training loop\n",
        "    for epoch in range(start_epoch, max_epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        # Training\n",
        "        for step, (X, Y) in enumerate(train_loader):\n",
        "            X = X.to(device, non_blocking=True)\n",
        "            Y = Y.to(device, non_blocking=True).permute(0, 2, 1)\n",
        "            \n",
        "            with autocast(enabled=torch.cuda.is_available()):\n",
        "                pred = model(X, adj)\n",
        "                loss = masked_mae(pred, Y) / grad_accum_steps\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            if (step + 1) % grad_accum_steps == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for X, Y in val_loader:\n",
        "                X = X.to(device, non_blocking=True)\n",
        "                Y = Y.to(device, non_blocking=True).permute(0, 2, 1)\n",
        "                val_loss += masked_mae(model(X, adj), Y).item()\n",
        "        \n",
        "        val_loss /= len(val_loader)\n",
        "        scheduler.step(val_loss)\n",
        "        logger.log(epoch, running_loss, val_loss)\n",
        "        \n",
        "        # Save best model\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        \n",
        "        # Save checkpoint\n",
        "        save_checkpoint({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"model\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "            \"scheduler\": scheduler.state_dict(),\n",
        "            \"best_val\": best_val,\n",
        "            \"early_stop_counter\": early_stop.counter\n",
        "        })\n",
        "        \n",
        "        # Logging\n",
        "        logging.info(f\"Epoch {epoch} | Train Loss {running_loss:.4f} | Val MAE {val_loss:.4f}\")\n",
        "        print(f\"Epoch {epoch:03d} | Train Loss {running_loss:.4f} | Val MAE {val_loss:.4f}\")\n",
        "        \n",
        "        # Early stopping\n",
        "        if early_stop.step(val_loss):\n",
        "            print(\"üõë Early stopping triggered\")\n",
        "            break\n",
        "    \n",
        "    print(\"‚úÖ Training complete!\")\n",
        "    return model, best_val\n",
        "\n",
        "print(\"‚úÖ Training pipeline loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(\n",
        "    model,\n",
        "    data_path=\"data/metr_la/metr_la.npz\",\n",
        "    adj_path=\"data/metr_la/adj.npy\",\n",
        "    model_path=\"best_model.pt\",\n",
        "    mc_runs=20\n",
        "):\n",
        "    \"\"\"Evaluate model with uncertainty quantification\"\"\"\n",
        "    \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # Load model weights\n",
        "    if os.path.exists(model_path):\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        print(f\"‚úÖ Loaded model from {model_path}\")\n",
        "    \n",
        "    # Load data\n",
        "    data = np.load(data_path)[\"data\"]\n",
        "    adj = torch.tensor(np.load(adj_path)).float().to(device)\n",
        "    \n",
        "    # Test split (last 20%)\n",
        "    T = len(data)\n",
        "    train_data = data[:int(0.7 * T)]\n",
        "    test_data = data[int(0.8 * T):]\n",
        "    \n",
        "    # Create test dataset\n",
        "    train_ds = TrafficDataset(train_data)\n",
        "    test_ds = TrafficDataset(test_data, mean=train_ds.mean, std=train_ds.std)\n",
        "    test_loader = DataLoader(test_ds, batch_size=32, pin_memory=True)\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # Metrics\n",
        "    mae = rmse = mape = 0.0\n",
        "    uncertainty = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for X, Y in test_loader:\n",
        "            X = X.to(device)\n",
        "            Y = Y.to(device).permute(0, 2, 1)\n",
        "            \n",
        "            # Monte-Carlo dropout for uncertainty\n",
        "            mean, std = mc_dropout_predict(model, X, adj, runs=mc_runs)\n",
        "            \n",
        "            # Compute metrics\n",
        "            mae += masked_mae(mean, Y).item()\n",
        "            rmse += masked_rmse(mean, Y).item()\n",
        "            mape += masked_mape(mean, Y).item()\n",
        "            uncertainty += std.mean().item()\n",
        "    \n",
        "    mae /= len(test_loader)\n",
        "    rmse /= len(test_loader)\n",
        "    mape /= len(test_loader)\n",
        "    uncertainty /= len(test_loader)\n",
        "    \n",
        "    print(\"=\" * 50)\n",
        "    print(\"Evaluation Results:\")\n",
        "    print(f\"  MAE:  {mae:.4f}\")\n",
        "    print(f\"  RMSE: {rmse:.4f}\")\n",
        "    print(f\"  MAPE: {mape:.4f}\")\n",
        "    print(f\"  Avg Predictive Uncertainty: {uncertainty:.4f}\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    return {\n",
        "        \"mae\": mae,\n",
        "        \"rmse\": rmse,\n",
        "        \"mape\": mape,\n",
        "        \"uncertainty\": uncertainty\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Evaluation pipeline loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Traffic Routing Controller (Model-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Traffic Routing & Flow Control Engine\n",
        "# Consumes future traffic predictions and produces stable, congestion-aware route decisions\n",
        "\n",
        "def aggregate_congestion(pred_traffic, mode=\"risk\"):\n",
        "    \"\"\"\n",
        "    Convert future trajectory into a single congestion risk score\n",
        "    \n",
        "    Args:\n",
        "        pred_traffic: np.ndarray [N, H] - predicted traffic for H time steps\n",
        "        mode: aggregation mode (\"mean\" or \"risk\")\n",
        "    Returns:\n",
        "        np.ndarray [N] - congestion risk score per node\n",
        "    \"\"\"\n",
        "    if mode == \"mean\":\n",
        "        return pred_traffic.mean(axis=1)\n",
        "    elif mode == \"risk\":\n",
        "        # Penalize spikes more than average\n",
        "        return 0.6 * pred_traffic.mean(axis=1) + 0.4 * pred_traffic.max(axis=1)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown aggregation mode: {mode}\")\n",
        "\n",
        "def edge_cost(distance, congestion, alpha=0.7):\n",
        "    \"\"\"Compute edge cost based on distance and congestion\"\"\"\n",
        "    return distance * (1.0 + alpha * congestion)\n",
        "\n",
        "def build_weighted_graph(adj, dist, node_congestion):\n",
        "    \"\"\"\n",
        "    Build NetworkX graph with congestion-aware edge weights\n",
        "    \n",
        "    Args:\n",
        "        adj: [N, N] adjacency matrix (0/1)\n",
        "        dist: [N, N] distance matrix\n",
        "        node_congestion: [N] congestion score per node\n",
        "    Returns:\n",
        "        NetworkX Graph with weighted edges\n",
        "    \"\"\"\n",
        "    if nx is None:\n",
        "        raise ImportError(\"networkx is required for traffic routing\")\n",
        "    \n",
        "    G = nx.Graph()\n",
        "    N = adj.shape[0]\n",
        "    \n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            if adj[i, j] == 1:\n",
        "                G.add_edge(\n",
        "                    i, j,\n",
        "                    weight=edge_cost(dist[i, j], node_congestion[j]),\n",
        "                    distance=dist[i, j]\n",
        "                )\n",
        "    return G\n",
        "\n",
        "def compute_routes(G, src, dst):\n",
        "    \"\"\"Compute optimized and shortest routes\"\"\"\n",
        "    if nx is None:\n",
        "        raise ImportError(\"networkx is required for traffic routing\")\n",
        "    \n",
        "    optimized_route = nx.shortest_path(G, src, dst, weight=\"weight\")\n",
        "    shortest_route = nx.shortest_path(G, src, dst, weight=\"distance\")\n",
        "    return optimized_route, shortest_route\n",
        "\n",
        "def assign_route(p_optimized=0.75):\n",
        "    \"\"\"Probabilistic assignment to prevent route collapse\"\"\"\n",
        "    return \"optimized\" if random.random() < p_optimized else \"shortest\"\n",
        "\n",
        "class RouteStabilityGuard:\n",
        "    \"\"\"Prevents sudden routing policy shifts that cause oscillations\"\"\"\n",
        "    def __init__(self, initial_split=0.75, max_change=0.15):\n",
        "        self.current_split = initial_split\n",
        "        self.max_change = max_change\n",
        "    \n",
        "    def smooth(self, target_split):\n",
        "        delta = target_split - self.current_split\n",
        "        delta = np.clip(delta, -self.max_change, self.max_change)\n",
        "        self.current_split += delta\n",
        "        return self.current_split\n",
        "\n",
        "class TrafficRouter:\n",
        "    \"\"\"\n",
        "    Model-2 Controller: Consumes Model-1 predictions and returns user routes\n",
        "    \n",
        "    Design goals:\n",
        "    - Minimal and deterministic\n",
        "    - Industry-grade\n",
        "    - Congestion-aware routing\n",
        "    - Stability guards to avoid oscillations\n",
        "    \"\"\"\n",
        "    def __init__(self, adj, dist, alpha=0.7):\n",
        "        self.adj = adj\n",
        "        self.dist = dist\n",
        "        self.alpha = alpha\n",
        "        self.guard = RouteStabilityGuard()\n",
        "    \n",
        "    def route(self, pred_traffic, src, dst):\n",
        "        \"\"\"\n",
        "        Compute route based on traffic predictions\n",
        "        \n",
        "        Args:\n",
        "            pred_traffic: np.ndarray [N, H] - Model-1 output (predicted traffic)\n",
        "            src, dst: source & destination nodes\n",
        "        Returns:\n",
        "            dict with route information\n",
        "        \"\"\"\n",
        "        # Aggregate future congestion\n",
        "        node_cong = aggregate_congestion(pred_traffic)\n",
        "        \n",
        "        # Build congestion-aware graph\n",
        "        G = build_weighted_graph(self.adj, self.dist, node_cong)\n",
        "        \n",
        "        # Compute dual routes\n",
        "        opt_route, short_route = compute_routes(G, src, dst)\n",
        "        \n",
        "        # Stable flow split\n",
        "        split = self.guard.smooth(0.75)\n",
        "        \n",
        "        # Assign route\n",
        "        choice = assign_route(split)\n",
        "        \n",
        "        return {\n",
        "            \"chosen_route\": opt_route if choice == \"optimized\" else short_route,\n",
        "            \"optimized_route\": opt_route,\n",
        "            \"shortest_route\": short_route,\n",
        "            \"split_ratio\": split,\n",
        "            \"policy\": choice\n",
        "        }\n",
        "\n",
        "print(\"‚úÖ Traffic routing controller loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Traffic Simulator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrafficSimulator:\n",
        "    \"\"\"\n",
        "    Closed-loop traffic flow simulator\n",
        "    \n",
        "    Simulates how routing decisions modify traffic state.\n",
        "    This is a SYSTEM simulator, not ML.\n",
        "    \"\"\"\n",
        "    def __init__(self, adj, decay=0.85):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            adj: adjacency matrix [N, N]\n",
        "            decay: how fast congestion dissipates (0-1)\n",
        "        \"\"\"\n",
        "        self.adj = adj\n",
        "        self.decay = decay\n",
        "    \n",
        "    def apply_routes(self, traffic, route, load=1.0):\n",
        "        \"\"\"\n",
        "        Apply route to traffic state\n",
        "        \n",
        "        Args:\n",
        "            traffic: [N] current congestion\n",
        "            route: list of nodes (route path)\n",
        "            load: traffic volume\n",
        "        Returns:\n",
        "            Updated traffic state\n",
        "        \"\"\"\n",
        "        traffic = traffic.copy()\n",
        "        for node in route:\n",
        "            traffic[node] += load\n",
        "        return traffic\n",
        "    \n",
        "    def step(self, traffic, routes):\n",
        "        \"\"\"\n",
        "        Simulate one time step\n",
        "        \n",
        "        Args:\n",
        "            traffic: [N] current congestion\n",
        "            routes: list of (route, load) tuples\n",
        "        Returns:\n",
        "            Updated traffic state after one time step\n",
        "        \"\"\"\n",
        "        # Decay old congestion\n",
        "        traffic = traffic * self.decay\n",
        "        \n",
        "        # Apply routes\n",
        "        for route, load in routes:\n",
        "            traffic = self.apply_routes(traffic, route, load)\n",
        "        \n",
        "        return traffic\n",
        "\n",
        "print(\"‚úÖ Traffic simulator loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Example Usage & Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Example: Quick Model Test\n",
        "# =======================\n",
        "def test_model_forward():\n",
        "    \"\"\"Test model forward pass\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # Create dummy data\n",
        "    B, T, N, F = 2, 48, 20, 5\n",
        "    x = torch.randn(B, T, N, F).to(device)\n",
        "    adj = torch.eye(N).to(device)\n",
        "    \n",
        "    # Create model\n",
        "    model = NewtonGraphMamba(\n",
        "        in_features=F,\n",
        "        d_model=32,\n",
        "        num_nodes=N,\n",
        "        num_layers=2,\n",
        "        prediction_horizon=12\n",
        "    ).to(device)\n",
        "    \n",
        "    # Forward pass\n",
        "    y = model(x, adj)\n",
        "    \n",
        "    print(f\"‚úÖ Forward pass successful!\")\n",
        "    print(f\"   Input shape:  {x.shape}\")\n",
        "    print(f\"   Output shape: {y.shape}\")\n",
        "    print(f\"   Expected:     [B={B}, N={N}, H=12]\")\n",
        "    \n",
        "    return model, y\n",
        "\n",
        "# Uncomment to test:\n",
        "# test_model_forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Example: Training (commented out)\n",
        "# =======================\n",
        "# Uncomment and run to train the model:\n",
        "#\n",
        "# model, best_val = train_model(\n",
        "#     data_path=\"data/metr_la/metr_la.npz\",\n",
        "#     adj_path=\"data/metr_la/adj.npy\",\n",
        "#     max_epochs=100,\n",
        "#     device_mem_gb=4,\n",
        "#     seed=42\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Example: Evaluation (commented out)\n",
        "# =======================\n",
        "# Uncomment and run to evaluate the model:\n",
        "#\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# data = np.load(\"data/metr_la/metr_la.npz\")[\"data\"]\n",
        "# model = NewtonGraphMamba(\n",
        "#     in_features=data.shape[-1],\n",
        "#     num_nodes=data.shape[1]\n",
        "# ).to(device)\n",
        "#\n",
        "# results = evaluate_model(\n",
        "#     model,\n",
        "#     data_path=\"data/metr_la/metr_la.npz\",\n",
        "#     adj_path=\"data/metr_la/adj.npy\",\n",
        "#     model_path=\"best_model.pt\",\n",
        "#     mc_runs=20\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Example: Closed-Loop Traffic Control\n",
        "# =======================\n",
        "def demo_closed_loop_control():\n",
        "    \"\"\"\n",
        "    Demo of closed-loop traffic control system:\n",
        "    1. Model-1 predicts future traffic\n",
        "    2. Model-2 (Router) computes routes based on predictions\n",
        "    3. Simulator updates traffic state\n",
        "    4. Loop continues\n",
        "    \"\"\"\n",
        "    if nx is None:\n",
        "        print(\"‚ö†Ô∏è  networkx not available. Skipping closed-loop demo.\")\n",
        "        return\n",
        "    \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # Setup (dummy data for demo)\n",
        "    N = 20\n",
        "    H = 12  # prediction horizon\n",
        "    \n",
        "    # Create dummy adjacency and distance matrices\n",
        "    adj = np.random.randint(0, 2, (N, N))\n",
        "    adj = adj | adj.T  # Make symmetric\n",
        "    np.fill_diagonal(adj, 0)  # No self-loops\n",
        "    \n",
        "    dist = np.random.rand(N, N) * 10\n",
        "    dist = (dist + dist.T) / 2  # Symmetric\n",
        "    \n",
        "    # Initialize model-1 (forecaster)\n",
        "    model = NewtonGraphMamba(\n",
        "        in_features=5,\n",
        "        num_nodes=N,\n",
        "        d_model=32,\n",
        "        num_layers=2\n",
        "    ).to(device)\n",
        "    \n",
        "    # Initialize model-2 (router)\n",
        "    router = TrafficRouter(adj, dist, alpha=0.7)\n",
        "    \n",
        "    # Initialize simulator\n",
        "    simulator = TrafficSimulator(adj, decay=0.85)\n",
        "    \n",
        "    # Initial traffic state\n",
        "    current_traffic = np.random.rand(N)\n",
        "    \n",
        "    print(\"üö¶ Closed-Loop Traffic Control Demo\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Simulate a few time steps\n",
        "    for step in range(5):\n",
        "        print(f\"\\n--- Time Step {step + 1} ---\")\n",
        "        \n",
        "        # Step 1: Prepare input for Model-1\n",
        "        # (In real scenario, this would be historical traffic data)\n",
        "        B, T = 1, 48\n",
        "        historical_data = torch.randn(B, T, N, 5).to(device)\n",
        "        adj_tensor = torch.tensor(adj).float().to(device)\n",
        "        \n",
        "        # Step 2: Model-1 predicts future traffic\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred_traffic = model(historical_data, adj_tensor)\n",
        "            pred_traffic = pred_traffic[0].cpu().numpy()  # [N, H]\n",
        "        \n",
        "        print(f\"Predicted traffic shape: {pred_traffic.shape}\")\n",
        "        print(f\"Avg predicted congestion: {pred_traffic.mean():.3f}\")\n",
        "        \n",
        "        # Step 3: Model-2 computes routes\n",
        "        src, dst = 0, N - 1\n",
        "        route_info = router.route(pred_traffic, src, dst)\n",
        "        \n",
        "        print(f\"Route from {src} to {dst}:\")\n",
        "        print(f\"  Chosen: {route_info['chosen_route'][:5]}...\" if len(route_info['chosen_route']) > 5 else f\"  Chosen: {route_info['chosen_route']}\")\n",
        "        print(f\"  Policy: {route_info['policy']}\")\n",
        "        print(f\"  Split ratio: {route_info['split_ratio']:.2f}\")\n",
        "        \n",
        "        # Step 4: Simulator updates traffic\n",
        "        routes_to_apply = [(route_info['chosen_route'], 1.0)]\n",
        "        current_traffic = simulator.step(current_traffic, routes_to_apply)\n",
        "        \n",
        "        print(f\"Current traffic state: avg={current_traffic.mean():.3f}, max={current_traffic.max():.3f}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Closed-loop demo complete!\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "# Uncomment to run demo:\n",
        "# demo_closed_loop_control()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìù Notes\n",
        "\n",
        "- **Data Paths**: Update `data_path` and `adj_path` in training/evaluation functions to match your data location\n",
        "- **GPU Memory**: Adjust `device_mem_gb` parameter based on your GPU capacity\n",
        "- **Model Checkpoints**: Training automatically saves checkpoints and best model\n",
        "- **NetworkX**: Required for traffic routing features (`pip install networkx`)\n",
        "- **Mamba SSM**: Optional but recommended for better performance (`pip install mamba-ssm`)\n",
        "\n",
        "## üéØ Quick Start\n",
        "\n",
        "1. **Load all cells** to import all functions and classes\n",
        "2. **Test model** by running the `test_model_forward()` function\n",
        "3. **Train model** by uncommenting and running the training cell (update data paths first)\n",
        "4. **Evaluate model** by uncommenting and running the evaluation cell\n",
        "5. **Demo closed-loop** by uncommenting and running the closed-loop control demo\n",
        "\n",
        "---\n",
        "\n",
        "**Project consolidated and ready to use!** üöÄ"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
